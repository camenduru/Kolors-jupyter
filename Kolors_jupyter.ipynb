{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Kolors-jupyter/blob/main/Kolors_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Kolors\n",
        "%cd /content/Kolors\n",
        "!pip install diffusers==0.28.2 transformers==4.26.1 accelerate==0.27.2 omegaconf==2.3.0 sentencepiece==0.1.99 fire\n",
        "!pip install -e .\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/scheduler/scheduler_config.json -d /content/Kolors/weights/Kolors/scheduler -o scheduler_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/config.json -d /content/Kolors/weights/Kolors/text_encoder -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/configuration_chatglm.py -d /content/Kolors/weights/Kolors/text_encoder -o configuration_chatglm.py\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/modeling_chatglm.py -d /content/Kolors/weights/Kolors/text_encoder -o modeling_chatglm.py\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00001-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00001-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00002-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00002-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00003-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00003-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00004-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00004-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00005-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00005-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00006-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00006-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/pytorch_model-00007-of-00007.bin -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model-00007-of-00007.bin\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/pytorch_model.bin.index.json -d /content/Kolors/weights/Kolors/text_encoder -o pytorch_model.bin.index.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/quantization.py -d /content/Kolors/weights/Kolors/text_encoder -o quantization.py\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/tokenization_chatglm.py -d /content/Kolors/weights/Kolors/text_encoder -o tokenization_chatglm.py\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/tokenizer.model -d /content/Kolors/weights/Kolors/text_encoder -o tokenizer.model\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/text_encoder/tokenizer_config.json -d /content/Kolors/weights/Kolors/text_encoder -o tokenizer_config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/text_encoder/vocab.txt -d /content/Kolors/weights/Kolors/text_encoder -o vocab.txt\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/unet/config.json -d /content/Kolors/weights/Kolors/unet -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/unet/diffusion_pytorch_model.safetensors -d /content/Kolors/weights/Kolors/unet -o diffusion_pytorch_model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/raw/main/vae/config.json -d /content/Kolors/weights/Kolors/vae -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/vae/diffusion_pytorch_model.safetensors -d /content/Kolors/weights/Kolors/vae -o diffusion_pytorch_model.safetensors\n",
        "\n",
        "# !python scripts/sample.py ' A girl with long straight hair in 80’s anime vintage style holding sign writing \"Kolors\" '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, torch, random\n",
        "from kolors.pipelines.pipeline_stable_diffusion_xl_chatglm_256 import StableDiffusionXLPipeline\n",
        "from kolors.models.modeling_chatglm import ChatGLMModel\n",
        "from kolors.models.tokenization_chatglm import ChatGLMTokenizer\n",
        "from diffusers import UNet2DConditionModel, AutoencoderKL\n",
        "from diffusers import EulerDiscreteScheduler\n",
        "\n",
        "ckpt_dir = f'/content/Kolors/weights/Kolors'\n",
        "text_encoder = ChatGLMModel.from_pretrained(\n",
        "    f'{ckpt_dir}/text_encoder',\n",
        "    torch_dtype=torch.float16).half()\n",
        "tokenizer = ChatGLMTokenizer.from_pretrained(f'{ckpt_dir}/text_encoder')\n",
        "vae = AutoencoderKL.from_pretrained(f\"{ckpt_dir}/vae\", revision=None).half()\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(f\"{ckpt_dir}/scheduler\")\n",
        "unet = UNet2DConditionModel.from_pretrained(f\"{ckpt_dir}/unet\", revision=None).half()\n",
        "pipe = StableDiffusionXLPipeline(\n",
        "        vae=vae,\n",
        "        text_encoder=text_encoder,\n",
        "        tokenizer=tokenizer,\n",
        "        unet=unet,\n",
        "        scheduler=scheduler,\n",
        "        force_zeros_for_empty_prompt=False)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.enable_model_cpu_offload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = random.randint(0, 18446744073709551615)\n",
        "image = pipe(\n",
        "    prompt=' A girl with long straight hair in 80’s anime vintage style holding sign writing \"Kolors\" ',\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=5.0,\n",
        "    num_images_per_prompt=1,\n",
        "    generator= torch.Generator(pipe.device).manual_seed(seed)).images[0]\n",
        "image.save(f'/content/Kolors/scripts/outputs/sample_test_{seed}.jpg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
